{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing disaster mapping\n",
      "Seasons in training data: ['Fall' 'Spring' 'Summer' 'Winter']\n",
      "Model classes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 19 20]\n",
      "Disaster mapping: {0: np.int64(0), 1: np.int64(1), 2: np.int64(2), 3: np.int64(3), 4: np.int64(4), 5: np.int64(5), 6: np.int64(6), 7: np.int64(7), 8: np.int64(8), 9: np.int64(9), 10: np.int64(10), 11: np.int64(11), 12: np.int64(12), 13: np.int64(13), 14: np.int64(14), 15: np.int64(15), 16: np.int64(17), 17: np.int64(18), 18: np.int64(19), 19: np.int64(20)}\n",
      "Generating 5-year forecast (2024-2028)...\n",
      "Forecast results saved successfully!\n",
      "Forecast complete. Results saved.\n",
      "Generated 28500 forecast records\n",
      "Covering 475 locations\n",
      "Forecast period: 2024 to 2028\n",
      "\n",
      "Sample forecast data:\n",
      "        location  year  month  disaster_type  prob_0  prob_1  prob_2  prob_3  \\\n",
      "0       Location  2024      1            6.0    0.13    0.04    0.05    0.02   \n",
      "1         ESIAMA  2024      1            NaN    0.16    0.03    0.03    0.00   \n",
      "2  AGONA NKWANTA  2024      1           19.0    0.09    0.03    0.01    0.00   \n",
      "3        MPATASE  2024      1            6.0    0.14    0.04    0.05    0.02   \n",
      "4          ABURA  2024      1            6.0    0.10    0.03    0.01    0.00   \n",
      "\n",
      "   prob_4  prob_5  ...  prob_10  prob_11  prob_12  prob_13  prob_14  prob_15  \\\n",
      "0    0.02     0.0  ...     0.00     0.01     0.00      0.0      0.0     0.17   \n",
      "1    0.00     0.0  ...     0.03     0.00     0.00      0.0      0.0     0.09   \n",
      "2    0.00     0.0  ...     0.11     0.00     0.01      0.0      0.0     0.13   \n",
      "3    0.02     0.0  ...     0.00     0.01     0.00      0.0      0.0     0.17   \n",
      "4    0.01     0.0  ...     0.06     0.00     0.00      0.0      0.0     0.16   \n",
      "\n",
      "   prob_17  prob_18  prob_19  prob_20  \n",
      "0     0.01     0.12     0.05     0.09  \n",
      "1     0.04     0.13     0.02     0.19  \n",
      "2     0.01     0.21     0.02     0.09  \n",
      "3     0.02     0.11     0.05     0.09  \n",
      "4     0.00     0.18     0.02     0.07  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Location summary sample:\n",
      "         location  most_likely_disaster\n",
      "0   AJOMORO ESIAM                  15.0\n",
      "1          ABEASE                  15.0\n",
      "2       ABENBOBOM                  15.0\n",
      "3          ABOADI                  15.0\n",
      "4         ABOADZE                  15.0\n",
      "\n",
      "Disaster percentages sample:\n",
      "disaster_type   0.0       1.0   4.0        6.0       7.0       9.0   10.0  \\\n",
      "location                                                                    \n",
      " AJOMORO ESIAM   0.0  3.333333   0.0  16.666667  1.666667  3.333333   0.0   \n",
      "ABEASE           0.0  3.333333   0.0  16.666667  1.666667  3.333333   0.0   \n",
      "ABENBOBOM        0.0  0.000000   0.0  10.000000  0.000000  5.000000   0.0   \n",
      "ABOADI           0.0  0.000000   0.0  10.000000  0.000000  5.000000   0.0   \n",
      "ABOADZE          0.0  0.000000   0.0  10.000000  0.000000  5.000000   0.0   \n",
      "\n",
      "disaster_type   14.0       15.0  18.0      19.0       20.0  \n",
      "location                                                    \n",
      " AJOMORO ESIAM   0.0  53.333333   0.0  6.666667  10.000000  \n",
      "ABEASE           0.0  53.333333   0.0  6.666667  10.000000  \n",
      "ABENBOBOM        0.0  70.000000   0.0  6.666667   8.333333  \n",
      "ABOADI           0.0  71.666667   0.0  6.666667   6.666667  \n",
      "ABOADZE          0.0  71.666667   0.0  6.666667   6.666667  \n",
      "\n",
      "Verifying disaster types are strings:\n",
      "Unique disaster types in forecast: [ 6. nan 19. 15.  0. 20. 18.  9.  1.  4. 10.  7. 14.]\n",
      "Data type of disaster_type column: float64\n",
      "\n",
      "SUCCESS: All disaster types are strings!\n"
     ]
    }
   ],
   "source": [
    "# notebooks/04_forecasting.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# Create necessary directories if they don't exist\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Load data and models\n",
    "historical_df = pd.read_csv('../data/processed/cleaned_disaster_data.csv')\n",
    "model = joblib.load('../models/disaster_predictor.pkl')\n",
    "location_encoder = joblib.load('../models/location_encoder.pkl')\n",
    "disaster_encoder = joblib.load('../models/disaster_encoder.pkl')\n",
    "season_encoder = joblib.load('../models/season_encoder.pkl')\n",
    "\n",
    "# Try to load disaster mapping, if it doesn't exist, create it from model classes\n",
    "try:\n",
    "    disaster_mapping = joblib.load('../models/disaster_mapping.pkl')\n",
    "    print(\"Loaded existing disaster mapping\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Disaster mapping not found, creating from model classes\")\n",
    "    disaster_mapping = {i: disaster_type for i, disaster_type in enumerate(model.classes_)}\n",
    "    joblib.dump(disaster_mapping, '../models/disaster_mapping.pkl')\n",
    "    print(\"Created and saved new disaster mapping\")\n",
    "\n",
    "# Check what seasons were in the training data\n",
    "print(\"Seasons in training data:\", season_encoder.classes_)\n",
    "print(\"Model classes:\", model.classes_)\n",
    "print(\"Disaster mapping:\", disaster_mapping)\n",
    "\n",
    "# Create a manual season mapping dictionary\n",
    "season_mapping = {\n",
    "    'Spring': 0,\n",
    "    'Summer': 1,\n",
    "    'Fall': 2,\n",
    "    'Winter': 3\n",
    "}\n",
    "\n",
    "# Forecasting Functions (included directly in the notebook)\n",
    "def generate_future_forecast(historical_data, model, location_encoder, disaster_encoder, season_encoder, \n",
    "                            start_year=2024, end_year=2028):\n",
    "    \"\"\"\n",
    "    Generate disaster forecasts for the next 5 years (2024-2028) for each month and location\n",
    "    \"\"\"\n",
    "    # Get unique locations\n",
    "    locations = historical_data['location'].unique()\n",
    "    \n",
    "    # Create future dates\n",
    "    future_dates = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for month in range(1, 13):\n",
    "            future_dates.append({\n",
    "                'year': year,\n",
    "                'month': month,\n",
    "                'day': 15,  # Mid-month representation\n",
    "                'date': pd.to_datetime(f'{year}-{month}-15')\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame for all location-date combinations\n",
    "    forecast_data = []\n",
    "    for date_info in future_dates:\n",
    "        for location in locations:\n",
    "            record = {\n",
    "                'location': location,\n",
    "                'year': date_info['year'],\n",
    "                'month': date_info['month'],\n",
    "                'day': date_info['day'],\n",
    "                'date': date_info['date']\n",
    "            }\n",
    "            forecast_data.append(record)\n",
    "    \n",
    "    forecast_df = pd.DataFrame(forecast_data)\n",
    "    \n",
    "    # Add day of week\n",
    "    forecast_df['day_of_week'] = forecast_df['date'].dt.dayofweek\n",
    "    \n",
    "    # Apply feature engineering\n",
    "    forecast_df['location_encoded'] = location_encoder.transform(forecast_df['location'])\n",
    "    \n",
    "    # Create season\n",
    "    forecast_df['season'] = forecast_df['month'].apply(lambda x: \n",
    "        'Spring' if x in [3,4,5] else\n",
    "        'Summer' if x in [6,7,8] else\n",
    "        'Fall' if x in [9,10,11] else 'Winter')\n",
    "    \n",
    "    # Encode season using manual mapping instead of the fitted encoder\n",
    "    forecast_df['season_encoded'] = forecast_df['season'].map(season_mapping)\n",
    "    \n",
    "    # Calculate location risk from historical data\n",
    "    location_risk = historical_data.groupby('location').size() / len(historical_data)\n",
    "    forecast_df['location_risk'] = forecast_df['location'].map(location_risk)\n",
    "    \n",
    "    # Calculate disaster frequency from historical data\n",
    "    disaster_freq = historical_data.groupby('disaster_type').size() / len(historical_data)\n",
    "    # Use average disaster frequency for all predictions\n",
    "    avg_disaster_freq = disaster_freq.mean()\n",
    "    forecast_df['disaster_freq'] = avg_disaster_freq\n",
    "    \n",
    "    # Prepare features for prediction\n",
    "    features = ['year', 'month', 'day', 'day_of_week', 'location_encoded', \n",
    "                'season_encoded', 'location_risk', 'disaster_freq']\n",
    "    \n",
    "    # Make predictions\n",
    "    X_forecast = forecast_df[features]\n",
    "    forecast_df['disaster_encoded'] = model.predict(X_forecast)\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    proba = model.predict_proba(X_forecast)\n",
    "    \n",
    "    # Use model's classes_ attribute to get disaster classes\n",
    "    disaster_classes = model.classes_\n",
    "    \n",
    "    # Add probability columns for each disaster type\n",
    "    for i, disaster in enumerate(disaster_classes):\n",
    "        if i < proba.shape[1]:  # Make sure we don't exceed the array bounds\n",
    "            forecast_df[f'prob_{disaster}'] = proba[:, i]\n",
    "        else:\n",
    "            print(f\"Warning: Skipping {disaster} due to index out of bounds\")\n",
    "    \n",
    "    # Convert encoded disaster type back to string using the disaster mapping\n",
    "    # This ensures we get actual disaster type names instead of numbers\n",
    "    forecast_df['disaster_type'] = forecast_df['disaster_encoded'].map(disaster_mapping)\n",
    "    \n",
    "    # Select relevant columns\n",
    "    prob_cols = [f'prob_{disaster}' for disaster in disaster_classes if f'prob_{disaster}' in forecast_df.columns]\n",
    "    result_df = forecast_df[['location', 'year', 'month', 'disaster_type'] + prob_cols]\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def aggregate_forecast_by_location(forecast_df):\n",
    "    \"\"\"\n",
    "    Aggregate forecast data by location to show most likely disasters\n",
    "    \"\"\"\n",
    "    # Group by location and get most common disaster type\n",
    "    location_summary = forecast_df.groupby('location')['disaster_type'].apply(\n",
    "        lambda x: x.mode()[0] if len(x) > 0 else 'Unknown'\n",
    "    ).reset_index(name='most_likely_disaster')\n",
    "    \n",
    "    # Calculate disaster type percentages by location\n",
    "    disaster_pct = forecast_df.groupby(['location', 'disaster_type']).size() / \\\n",
    "                  forecast_df.groupby('location').size() * 100\n",
    "    disaster_pct = disaster_pct.reset_index(name='percentage')\n",
    "    \n",
    "    # Pivot for easier visualization\n",
    "    disaster_pivot = disaster_pct.pivot(index='location', columns='disaster_type', values='percentage').fillna(0)\n",
    "    \n",
    "    return location_summary, disaster_pivot\n",
    "\n",
    "def save_forecast_results(forecast_df, location_summary, disaster_pivot, output_dir):\n",
    "    \"\"\"\n",
    "    Save forecast results to CSV files\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save results\n",
    "    forecast_df.to_csv(os.path.join(output_dir, 'forecast_results.csv'), index=False)\n",
    "    location_summary.to_csv(os.path.join(output_dir, 'location_forecast_summary.csv'), index=False)\n",
    "    disaster_pivot.to_csv(os.path.join(output_dir, 'disaster_percentages.csv'), index=True)\n",
    "    \n",
    "    print(\"Forecast results saved successfully!\")\n",
    "\n",
    "# Generate forecast\n",
    "print(\"Generating 5-year forecast (2024-2028)...\")\n",
    "forecast_df = generate_future_forecast(\n",
    "    historical_df, model, location_encoder, disaster_encoder, season_encoder\n",
    ")\n",
    "\n",
    "# Aggregate results\n",
    "location_summary, disaster_pivot = aggregate_forecast_by_location(forecast_df)\n",
    "\n",
    "# Save results\n",
    "save_forecast_results(forecast_df, location_summary, disaster_pivot, '../data/processed')\n",
    "\n",
    "print(\"Forecast complete. Results saved.\")\n",
    "print(f\"Generated {len(forecast_df)} forecast records\")\n",
    "print(f\"Covering {len(forecast_df['location'].unique())} locations\")\n",
    "print(f\"Forecast period: {forecast_df['year'].min()} to {forecast_df['year'].max()}\")\n",
    "\n",
    "# Display sample of results\n",
    "print(\"\\nSample forecast data:\")\n",
    "print(forecast_df.head())\n",
    "\n",
    "print(\"\\nLocation summary sample:\")\n",
    "print(location_summary.head())\n",
    "\n",
    "print(\"\\nDisaster percentages sample:\")\n",
    "print(disaster_pivot.head())\n",
    "\n",
    "# Verify disaster types are strings, not numbers\n",
    "print(\"\\nVerifying disaster types are strings:\")\n",
    "print(\"Unique disaster types in forecast:\", forecast_df['disaster_type'].unique())\n",
    "print(\"Data type of disaster_type column:\", forecast_df['disaster_type'].dtype)\n",
    "\n",
    "# Check if any disaster types are still numbers\n",
    "numeric_disasters = forecast_df[forecast_df['disaster_type'].apply(lambda x: isinstance(x, (int, np.int64, np.int32)))]\n",
    "if len(numeric_disasters) > 0:\n",
    "    print(\"\\nWARNING: Found numeric disaster types:\")\n",
    "    print(numeric_disasters['disaster_type'].value_counts())\n",
    "else:\n",
    "    print(\"\\nSUCCESS: All disaster types are strings!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasons in training data: ['Fall' 'Spring' 'Summer' 'Winter']\n",
      "Model classes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 19 20]\n",
      "Model classes length: 20\n",
      "Disaster encoder classes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 19 20]\n",
      "Disaster encoder classes length: 20\n",
      "Proper disaster mapping: {0: np.int64(0), 1: np.int64(1), 2: np.int64(2), 3: np.int64(3), 4: np.int64(4), 5: np.int64(5), 6: np.int64(6), 7: np.int64(7), 8: np.int64(8), 9: np.int64(9), 10: np.int64(10), 11: np.int64(11), 12: np.int64(12), 13: np.int64(13), 14: np.int64(14), 15: np.int64(15), 16: np.int64(17), 17: np.int64(18), 18: np.int64(19), 19: np.int64(20)}\n",
      "Generating 5-year forecast (2024-2028)...\n",
      "Forecast results saved successfully!\n",
      "Forecast complete. Results saved.\n",
      "Generated 28500 forecast records\n",
      "Covering 475 locations\n",
      "Forecast period: 2024 to 2028\n",
      "\n",
      "Sample forecast data:\n",
      "        location  year  month  disaster_type  prob_0  prob_1  prob_2  prob_3  \\\n",
      "0       Location  2024      1            6.0    0.13    0.04    0.05    0.02   \n",
      "1         ESIAMA  2024      1            NaN    0.16    0.03    0.03    0.00   \n",
      "2  AGONA NKWANTA  2024      1           19.0    0.09    0.03    0.01    0.00   \n",
      "3        MPATASE  2024      1            6.0    0.14    0.04    0.05    0.02   \n",
      "4          ABURA  2024      1            6.0    0.10    0.03    0.01    0.00   \n",
      "\n",
      "   prob_4  prob_5  ...  prob_10  prob_11  prob_12  prob_13  prob_14  prob_15  \\\n",
      "0    0.02     0.0  ...     0.00     0.01     0.00      0.0      0.0     0.17   \n",
      "1    0.00     0.0  ...     0.03     0.00     0.00      0.0      0.0     0.09   \n",
      "2    0.00     0.0  ...     0.11     0.00     0.01      0.0      0.0     0.13   \n",
      "3    0.02     0.0  ...     0.00     0.01     0.00      0.0      0.0     0.17   \n",
      "4    0.01     0.0  ...     0.06     0.00     0.00      0.0      0.0     0.16   \n",
      "\n",
      "   prob_17  prob_18  prob_19  prob_20  \n",
      "0     0.01     0.12     0.05     0.09  \n",
      "1     0.04     0.13     0.02     0.19  \n",
      "2     0.01     0.21     0.02     0.09  \n",
      "3     0.02     0.11     0.05     0.09  \n",
      "4     0.00     0.18     0.02     0.07  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Location summary sample:\n",
      "         location  most_likely_disaster\n",
      "0   AJOMORO ESIAM                  15.0\n",
      "1          ABEASE                  15.0\n",
      "2       ABENBOBOM                  15.0\n",
      "3          ABOADI                  15.0\n",
      "4         ABOADZE                  15.0\n",
      "\n",
      "Disaster percentages sample:\n",
      "disaster_type   0.0       1.0   4.0        6.0       7.0       9.0   10.0  \\\n",
      "location                                                                    \n",
      " AJOMORO ESIAM   0.0  3.333333   0.0  16.666667  1.666667  3.333333   0.0   \n",
      "ABEASE           0.0  3.333333   0.0  16.666667  1.666667  3.333333   0.0   \n",
      "ABENBOBOM        0.0  0.000000   0.0  10.000000  0.000000  5.000000   0.0   \n",
      "ABOADI           0.0  0.000000   0.0  10.000000  0.000000  5.000000   0.0   \n",
      "ABOADZE          0.0  0.000000   0.0  10.000000  0.000000  5.000000   0.0   \n",
      "\n",
      "disaster_type   14.0       15.0  18.0      19.0       20.0  \n",
      "location                                                    \n",
      " AJOMORO ESIAM   0.0  53.333333   0.0  6.666667  10.000000  \n",
      "ABEASE           0.0  53.333333   0.0  6.666667  10.000000  \n",
      "ABENBOBOM        0.0  70.000000   0.0  6.666667   8.333333  \n",
      "ABOADI           0.0  71.666667   0.0  6.666667   6.666667  \n",
      "ABOADZE          0.0  71.666667   0.0  6.666667   6.666667  \n",
      "\n",
      "Verifying disaster types are strings:\n",
      "Unique disaster types in forecast: [np.float64(6.0), np.float64(nan), np.float64(0.0), np.float64(1.0), np.float64(4.0), np.float64(7.0), np.float64(9.0), np.float64(10.0), np.float64(14.0), np.float64(15.0), np.float64(18.0), np.float64(19.0), np.float64(20.0)]\n",
      "Data type of disaster_type column: float64\n",
      "\n",
      "WARNING: Found numeric disaster types:\n",
      "disaster_type\n",
      "15.0    16287\n",
      "6.0      3122\n",
      "20.0     2620\n",
      "0.0      1782\n",
      "1.0      1592\n",
      "19.0      368\n",
      "9.0       178\n",
      "4.0       129\n",
      "7.0        58\n",
      "10.0        9\n",
      "18.0        4\n",
      "14.0        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# notebooks/04_forecasting.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# Create necessary directories if they don't exist\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Load data and models\n",
    "historical_df = pd.read_csv('../data/processed/cleaned_disaster_data.csv')\n",
    "model = joblib.load('../models/disaster_predictor.pkl')\n",
    "location_encoder = joblib.load('../models/location_encoder.pkl')\n",
    "disaster_encoder = joblib.load('../models/disaster_encoder.pkl')\n",
    "season_encoder = joblib.load('../models/season_encoder.pkl')\n",
    "\n",
    "# Check what seasons were in the training data\n",
    "print(\"Seasons in training data:\", season_encoder.classes_)\n",
    "print(\"Model classes:\", model.classes_)\n",
    "print(\"Model classes length:\", len(model.classes_))\n",
    "print(\"Disaster encoder classes:\", disaster_encoder.classes_)\n",
    "print(\"Disaster encoder classes length:\", len(disaster_encoder.classes_))\n",
    "\n",
    "# Create a manual season mapping dictionary\n",
    "season_mapping = {\n",
    "    'Spring': 0,\n",
    "    'Summer': 1,\n",
    "    'Fall': 2,\n",
    "    'Winter': 3\n",
    "}\n",
    "\n",
    "# Create a proper disaster mapping from the disaster encoder classes\n",
    "# We'll map each integer index in the disaster encoder to the corresponding disaster type\n",
    "disaster_mapping = {i: disaster_type for i, disaster_type in enumerate(disaster_encoder.classes_)}\n",
    "print(\"Proper disaster mapping:\", disaster_mapping)\n",
    "\n",
    "# Save the correct disaster mapping\n",
    "joblib.dump(disaster_mapping, '../models/disaster_mapping.pkl')\n",
    "\n",
    "# Forecasting Functions (included directly in the notebook)\n",
    "def generate_future_forecast(historical_data, model, location_encoder, disaster_encoder, season_encoder, \n",
    "                            start_year=2024, end_year=2028):\n",
    "    \"\"\"\n",
    "    Generate disaster forecasts for the next 5 years (2024-2028) for each month and location\n",
    "    \"\"\"\n",
    "    # Get unique locations\n",
    "    locations = historical_data['location'].unique()\n",
    "    \n",
    "    # Create future dates\n",
    "    future_dates = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for month in range(1, 13):\n",
    "            future_dates.append({\n",
    "                'year': year,\n",
    "                'month': month,\n",
    "                'day': 15,  # Mid-month representation\n",
    "                'date': pd.to_datetime(f'{year}-{month}-15')\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame for all location-date combinations\n",
    "    forecast_data = []\n",
    "    for date_info in future_dates:\n",
    "        for location in locations:\n",
    "            record = {\n",
    "                'location': location,\n",
    "                'year': date_info['year'],\n",
    "                'month': date_info['month'],\n",
    "                'day': date_info['day'],\n",
    "                'date': date_info['date']\n",
    "            }\n",
    "            forecast_data.append(record)\n",
    "    \n",
    "    forecast_df = pd.DataFrame(forecast_data)\n",
    "    \n",
    "    # Add day of week\n",
    "    forecast_df['day_of_week'] = forecast_df['date'].dt.dayofweek\n",
    "    \n",
    "    # Apply feature engineering\n",
    "    forecast_df['location_encoded'] = location_encoder.transform(forecast_df['location'])\n",
    "    \n",
    "    # Create season\n",
    "    forecast_df['season'] = forecast_df['month'].apply(lambda x: \n",
    "        'Spring' if x in [3,4,5] else\n",
    "        'Summer' if x in [6,7,8] else\n",
    "        'Fall' if x in [9,10,11] else 'Winter')\n",
    "    \n",
    "    # Encode season using manual mapping instead of the fitted encoder\n",
    "    forecast_df['season_encoded'] = forecast_df['season'].map(season_mapping)\n",
    "    \n",
    "    # Calculate location risk from historical data\n",
    "    location_risk = historical_data.groupby('location').size() / len(historical_data)\n",
    "    forecast_df['location_risk'] = forecast_df['location'].map(location_risk)\n",
    "    \n",
    "    # Calculate disaster frequency from historical data\n",
    "    disaster_freq = historical_data.groupby('disaster_type').size() / len(historical_data)\n",
    "    # Use average disaster frequency for all predictions\n",
    "    avg_disaster_freq = disaster_freq.mean()\n",
    "    forecast_df['disaster_freq'] = avg_disaster_freq\n",
    "    \n",
    "    # Prepare features for prediction\n",
    "    features = ['year', 'month', 'day', 'day_of_week', 'location_encoded', \n",
    "                'season_encoded', 'location_risk', 'disaster_freq']\n",
    "    \n",
    "    # Make predictions\n",
    "    X_forecast = forecast_df[features]\n",
    "    forecast_df['disaster_encoded'] = model.predict(X_forecast)\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    proba = model.predict_proba(X_forecast)\n",
    "    \n",
    "    # Use model's classes_ attribute to get disaster classes\n",
    "    disaster_classes = model.classes_\n",
    "    \n",
    "    # Add probability columns for each disaster type\n",
    "    for i, disaster in enumerate(disaster_classes):\n",
    "        if i < proba.shape[1]:  # Make sure we don't exceed the array bounds\n",
    "            forecast_df[f'prob_{disaster}'] = proba[:, i]\n",
    "        else:\n",
    "            print(f\"Warning: Skipping {disaster} due to index out of bounds\")\n",
    "    \n",
    "    # Convert encoded disaster type back to string using the disaster mapping\n",
    "    # This ensures we get actual disaster type names instead of numbers\n",
    "    forecast_df['disaster_type'] = forecast_df['disaster_encoded'].map(disaster_mapping)\n",
    "    \n",
    "    # Select relevant columns\n",
    "    prob_cols = [f'prob_{disaster}' for disaster in disaster_classes if f'prob_{disaster}' in forecast_df.columns]\n",
    "    result_df = forecast_df[['location', 'year', 'month', 'disaster_type'] + prob_cols]\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def aggregate_forecast_by_location(forecast_df):\n",
    "    \"\"\"\n",
    "    Aggregate forecast data by location to show most likely disasters\n",
    "    \"\"\"\n",
    "    # Group by location and get most common disaster type\n",
    "    location_summary = forecast_df.groupby('location')['disaster_type'].apply(\n",
    "        lambda x: x.mode()[0] if len(x) > 0 else 'Unknown'\n",
    "    ).reset_index(name='most_likely_disaster')\n",
    "    \n",
    "    # Calculate disaster type percentages by location\n",
    "    disaster_pct = forecast_df.groupby(['location', 'disaster_type']).size() / \\\n",
    "                  forecast_df.groupby('location').size() * 100\n",
    "    disaster_pct = disaster_pct.reset_index(name='percentage')\n",
    "    \n",
    "    # Pivot for easier visualization\n",
    "    disaster_pivot = disaster_pct.pivot(index='location', columns='disaster_type', values='percentage').fillna(0)\n",
    "    \n",
    "    return location_summary, disaster_pivot\n",
    "\n",
    "def save_forecast_results(forecast_df, location_summary, disaster_pivot, output_dir):\n",
    "    \"\"\"\n",
    "    Save forecast results to CSV files\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save results\n",
    "    forecast_df.to_csv(os.path.join(output_dir, 'forecast_results.csv'), index=False)\n",
    "    location_summary.to_csv(os.path.join(output_dir, 'location_forecast_summary.csv'), index=False)\n",
    "    disaster_pivot.to_csv(os.path.join(output_dir, 'disaster_percentages.csv'), index=True)\n",
    "    \n",
    "    print(\"Forecast results saved successfully!\")\n",
    "\n",
    "# Generate forecast\n",
    "print(\"Generating 5-year forecast (2024-2028)...\")\n",
    "forecast_df = generate_future_forecast(\n",
    "    historical_df, model, location_encoder, disaster_encoder, season_encoder\n",
    ")\n",
    "\n",
    "# Aggregate results\n",
    "location_summary, disaster_pivot = aggregate_forecast_by_location(forecast_df)\n",
    "\n",
    "# Save results\n",
    "save_forecast_results(forecast_df, location_summary, disaster_pivot, '../data/processed')\n",
    "\n",
    "print(\"Forecast complete. Results saved.\")\n",
    "print(f\"Generated {len(forecast_df)} forecast records\")\n",
    "print(f\"Covering {len(forecast_df['location'].unique())} locations\")\n",
    "print(f\"Forecast period: {forecast_df['year'].min()} to {forecast_df['year'].max()}\")\n",
    "\n",
    "# Display sample of results\n",
    "print(\"\\nSample forecast data:\")\n",
    "print(forecast_df.head())\n",
    "\n",
    "print(\"\\nLocation summary sample:\")\n",
    "print(location_summary.head())\n",
    "\n",
    "print(\"\\nDisaster percentages sample:\")\n",
    "print(disaster_pivot.head())\n",
    "\n",
    "# Verify disaster types are strings, not numbers\n",
    "print(\"\\nVerifying disaster types are strings:\")\n",
    "print(\"Unique disaster types in forecast:\", sorted(forecast_df['disaster_type'].unique()))\n",
    "print(\"Data type of disaster_type column:\", forecast_df['disaster_type'].dtype)\n",
    "\n",
    "# Check if any disaster types are still numbers\n",
    "numeric_disasters = forecast_df[forecast_df['disaster_type'].apply(lambda x: isinstance(x, (int, np.int64, np.int32, float)))]\n",
    "if len(numeric_disasters) > 0:\n",
    "    print(\"\\nWARNING: Found numeric disaster types:\")\n",
    "    print(numeric_disasters['disaster_type'].value_counts())\n",
    "else:\n",
    "    print(\"\\nSUCCESS: All disaster types are strings!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
