{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows of the dataset:\n",
      "                     0              1               2                 3  \\\n",
      "0                 Date  disaster_type  Incident_Count          Location   \n",
      "1            16/7/2021  DOMESTIC FIRE               1            ESIAMA   \n",
      "2  2019-11-02 00:00:00      WINDSTORM               1     AGONA NKWANTA   \n",
      "3             21/03/19      WINDSTORM               1           MPATASE   \n",
      "4             22/03/19      WINDSTORM               1             ABURA   \n",
      "5             23/03/19      WINDSTORM               1           AKWIDAA   \n",
      "6              25/4/19      WINDSTORM               1  BONWIRE JUNCTION   \n",
      "7  2019-01-05 00:00:00      WINDSTORM               1            AHOBRE   \n",
      "8  2019-01-05 00:00:00      WINDSTORM               1            ESIAMA   \n",
      "9              21/5/19      WINDSTORM               1            ESIAMA   \n",
      "\n",
      "                4  \n",
      "0  Severity_Index  \n",
      "1               1  \n",
      "2               1  \n",
      "3               1  \n",
      "4               1  \n",
      "5               1  \n",
      "6               1  \n",
      "7               1  \n",
      "8               1  \n",
      "9               1  \n",
      "\n",
      "Column names: [0, 1, 2, 3, 4]\n",
      "\n",
      "First 5 rows after column assignment:\n",
      "                  date  disaster_type              id       location  \\\n",
      "0                 Date  disaster_type  Incident_Count       Location   \n",
      "1            16/7/2021  DOMESTIC FIRE               1         ESIAMA   \n",
      "2  2019-11-02 00:00:00      WINDSTORM               1  AGONA NKWANTA   \n",
      "3             21/03/19      WINDSTORM               1        MPATASE   \n",
      "4             22/03/19      WINDSTORM               1          ABURA   \n",
      "\n",
      "   severity_index  \n",
      "0  Severity_Index  \n",
      "1               1  \n",
      "2               1  \n",
      "3               1  \n",
      "4               1  \n",
      "\n",
      "Data types:\n",
      "date              object\n",
      "disaster_type     object\n",
      "id                object\n",
      "location          object\n",
      "severity_index    object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CALEB ASSAN\\AppData\\Local\\Temp\\ipykernel_25336\\2585264520.py:45: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(date_str, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of invalid dates: 10\n",
      "\n",
      "Number of rows: 633\n",
      "Number of unique disaster types: 21\n",
      "Number of unique locations: 475\n",
      "\n",
      "Unique disaster types:\n",
      "disaster_type\n",
      "FIRE                            201\n",
      "FLOOD                           164\n",
      "RAIN_STORM                      116\n",
      "WIND_STORM                       88\n",
      "MAN_MADE                         22\n",
      "TIDAL_WAVE                        8\n",
      "COLLAPSE                          5\n",
      "ACCIDENT                          5\n",
      "LANDSLIDE                         4\n",
      "DROWNING                          3\n",
      "EPIDEMIC                          3\n",
      "MAN MADE(BUILDING COLLAPSE)       2\n",
      "PEST_INFESTATION                  2\n",
      "EXPLOSION                         2\n",
      "COMERCIAL FIRE                    2\n",
      "DISASTER_TYPE                     1\n",
      "PEST INFESTATION                  1\n",
      "LIGHTNING                         1\n",
      "INDUSTRIAL FIRE                   1\n",
      "DROWN                             1\n",
      "MAN MADE (BUILDING COLLAPSE)      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of processed data:\n",
      "        date  disaster_type              id       location  severity_index  \\\n",
      "0        NaT  DISASTER_TYPE  Incident_Count       Location  Severity_Index   \n",
      "1 2021-07-16           FIRE               1         ESIAMA               1   \n",
      "2 2019-11-02     WIND_STORM               1  AGONA NKWANTA               1   \n",
      "3 2019-03-21     WIND_STORM               1        MPATASE               1   \n",
      "4 2019-03-22     WIND_STORM               1          ABURA               1   \n",
      "\n",
      "     year  month   day  day_of_week  \n",
      "0     NaN    NaN   NaN          NaN  \n",
      "1  2021.0    7.0  16.0          4.0  \n",
      "2  2019.0   11.0   2.0          5.0  \n",
      "3  2019.0    3.0  21.0          3.0  \n",
      "4  2019.0    3.0  22.0          4.0  \n",
      "\n",
      "Data cleaning complete and saved to '../data/processed/cleaned_disaster_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# notebooks/01_data_preprocessing.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Create necessary directories if they don't exist\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Load data with header=None to read all rows as data\n",
    "df = pd.read_csv('../data/raw/Nadmo_cleaned_refined.csv', header=None)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(\"First 10 rows of the dataset:\")\n",
    "print(df.head(10))\n",
    "\n",
    "print(\"\\nColumn names:\", list(df.columns))\n",
    "\n",
    "# Check if the first row contains file info\n",
    "if df.iloc[0, 0] == 'Nadmo_cleaned_refined.csv':\n",
    "    # The first row is not data but contains file info, skip it\n",
    "    df = df.iloc[1:].reset_index(drop=True)\n",
    "    print(\"\\nRemoved first row with file info\")\n",
    "\n",
    "# Now assign column names based on the actual data structure\n",
    "# From your output, we can see:\n",
    "# Column 0: date (16/7/2021, 2019-11-02 00:00:00, etc.)\n",
    "# Column 1: disaster_type (DOMESTIC FIRE, WINDSTORM, etc.)\n",
    "# Column 2: id (1, 1, 1, etc.)\n",
    "# Column 3: location (ESIAMA, AGONA NKWANTA, etc.)\n",
    "# Column 4: severity_index (1, 1, 1, etc.)\n",
    "df.columns = ['date', 'disaster_type', 'id', 'location', 'severity_index']\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(\"\\nFirst 5 rows after column assignment:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Convert date to datetime\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, errors='coerce')\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df['date'] = df['date'].apply(parse_date)\n",
    "\n",
    "# Extract temporal features\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df['day_of_week'] = df['date'].dt.dayofweek\n",
    "\n",
    "# Check for any date parsing issues\n",
    "print(f\"\\nNumber of invalid dates: {df['date'].isna().sum()}\")\n",
    "\n",
    "# Standardize disaster types\n",
    "df['disaster_type'] = df['disaster_type'].str.upper().str.strip()\n",
    "\n",
    "# Create a comprehensive mapping dictionary\n",
    "disaster_mapping = {\n",
    "    'RAINSTORM': 'RAIN_STORM',\n",
    "    'RAINSTROM': 'RAIN_STORM',\n",
    "    'FLOODING': 'FLOOD',\n",
    "    'WINDSTORM': 'WIND_STORM',\n",
    "    'DOMESTIC FIRE': 'FIRE',\n",
    "    'COMMERCIAL FIRE': 'FIRE',\n",
    "    'BUSH FIRE': 'FIRE',\n",
    "    'MAN MADE': 'MAN_MADE',\n",
    "    'MAN-MADE': 'MAN_MADE',\n",
    "    'TIDAL WAVES': 'TIDAL_WAVE',\n",
    "    'TIDAL WAVE': 'TIDAL_WAVE',\n",
    "    'PEST&INSECT INFESTATION': 'PEST_INFESTATION',\n",
    "    'INSECT/PESTICIDE': 'PEST_INFESTATION',\n",
    "    'GAS EXPLOSION': 'EXPLOSION',\n",
    "    'CHEEMICAL EXPLOSION': 'EXPLOSION',\n",
    "    'ROAD ACCIDENT': 'ACCIDENT',\n",
    "    'BUILDING COLLAPSE': 'COLLAPSE',\n",
    "    'LANDSLIDE': 'LANDSLIDE',\n",
    "    'EPIDEMICS (AVIAN FLU)': 'EPIDEMIC',\n",
    "    'BIRD FLU': 'EPIDEMIC',\n",
    "    'DROWNING': 'DROWNING',\n",
    "    'GALAMSEY PIT COLLAPSE': 'COLLAPSE',\n",
    "    'LIGHTENING': 'LIGHTNING',\n",
    "    'RAINSTROM': 'RAIN_STORM',\n",
    "    'FLOODING': 'FLOOD',\n",
    "    'MAN MADE ': 'MAN_MADE',\n",
    "    'DOMESTIC FIRE  ': 'FIRE',\n",
    "    'RAINSTORM  ': 'RAIN_STORM',\n",
    "    'FLOOD  ': 'FLOOD',\n",
    "    'WINDSTORM  ': 'WIND_STORM',\n",
    "    'TIDAL WAVES': 'TIDAL_WAVE',\n",
    "    'PEST&INSECT INFESTATION': 'PEST_INFESTATION',\n",
    "    'INSECT/PESTICIDE': 'PEST_INFESTATION',\n",
    "    'GAS EXPLOSION': 'EXPLOSION',\n",
    "    'CHEEMICAL EXPLOSION': 'EXPLOSION',\n",
    "    'ROAD ACCIDENT': 'ACCIDENT',\n",
    "    'BUILDING COLLAPSE': 'COLLAPSE',\n",
    "    'LANDSLIDE': 'LANDSLIDE',\n",
    "    'EPIDEMICS (AVIAN FLU)': 'EPIDEMIC',\n",
    "    'BIRD FLU': 'EPIDEMIC',\n",
    "    'DROWNING': 'DROWNING',\n",
    "    'GALAMSEY PIT COLLAPSE': 'COLLAPSE',\n",
    "    'drown': 'DROWNING',\n",
    "    'domestic fire': 'FIRE',\n",
    "    'Rainstorm': 'RAIN_STORM',\n",
    "    'Rainstorm  ': 'RAIN_STORM',\n",
    "    'Flood': 'FLOOD',\n",
    "    'Flood  ': 'FLOOD',\n",
    "    'domestic fire': 'FIRE',\n",
    "    'MAN MADE(building collapse)': 'COLLAPSE',\n",
    "    'MAN MADE(DROWNING)': 'DROWNING',\n",
    "    'flood': 'FLOOD',\n",
    "    'flooding': 'FLOOD',\n",
    "    'domestic fire': 'FIRE',\n",
    "    'rainstorm': 'RAIN_STORM',\n",
    "    'windstorm': 'WIND_STORM',\n",
    "    'tidal wave': 'TIDAL_WAVE',\n",
    "    'man made': 'MAN_MADE',\n",
    "    'building collapse': 'COLLAPSE',\n",
    "    'landslide': 'LANDSLIDE',\n",
    "    'epidemics (avian flu)': 'EPIDEMIC',\n",
    "    'bird flu': 'EPIDEMIC',\n",
    "    'drowning': 'DROWNING',\n",
    "    'galamsey pit collapse': 'COLLAPSE',\n",
    "    'road accident': 'ACCIDENT',\n",
    "    'chemical explosion': 'EXPLOSION',\n",
    "    'gas explosion': 'EXPLOSION',\n",
    "    'pest&insect infestation': 'PEST_INFESTATION',\n",
    "    'insect/pesticide': 'PEST_INFESTATION',\n",
    "    'pest infestation': 'PEST_INFESTATION',\n",
    "    'lightening': 'LIGHTNING',\n",
    "    'bush fire': 'FIRE',\n",
    "    'commercial fire': 'FIRE',\n",
    "    'tidal waves': 'TIDAL_WAVE',\n",
    "    'man-made': 'MAN_MADE',\n",
    "    'man made': 'MAN_MADE'\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "df['disaster_type'] = df['disaster_type'].replace(disaster_mapping)\n",
    "\n",
    "# Handle missing locations\n",
    "df['location'] = df['location'].fillna('UNKNOWN')\n",
    "\n",
    "# Check for any remaining issues\n",
    "print(f\"\\nNumber of rows: {len(df)}\")\n",
    "print(f\"Number of unique disaster types: {df['disaster_type'].nunique()}\")\n",
    "print(f\"Number of unique locations: {df['location'].nunique()}\")\n",
    "\n",
    "# Display unique disaster types\n",
    "print(\"\\nUnique disaster types:\")\n",
    "print(df['disaster_type'].value_counts())\n",
    "\n",
    "# Display sample of processed data\n",
    "print(\"\\nSample of processed data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv('../data/processed/cleaned_disaster_data.csv', index=False)\n",
    "print(\"\\nData cleaning complete and saved to '../data/processed/cleaned_disaster_data.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
